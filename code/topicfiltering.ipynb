{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\1408\\AppData\\Local\\Temp\\ipykernel_17336\\2184716311.py:13: DtypeWarning: Columns (86,87,88) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframe = pd.read_csv(filename)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "\n",
    "tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "lemmatizer = nltk.WordNetLemmatizer()\n",
    "\n",
    "SUBREDDIT = 'ukraine'\n",
    "filename = f'./data/{SUBREDDIT}_raw_pushshift_data.csv'\n",
    "dataframe = pd.read_csv(filename)\n",
    "known_word_list = ['media', 'ss', 'gates']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "preprocessing with\n",
    "* lowercase\n",
    "* remove urls, usertags\n",
    "* join contractions\n",
    "* remove punctuation\n",
    "* tokenize\n",
    "* lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(submission):\n",
    "    submission = str(submission)\n",
    "\n",
    "    submission = \" \".join(submission.split())\n",
    "\n",
    "    submission = submission.lower()\n",
    "    submission = re.sub(r\"^(\\d{1,4})([.])(\\d{1,2})(([.])(\\d{1,4}))?$\", r\"\\1 \\3 \\6\", submission)\n",
    "\n",
    "    #source https://www.regextester.com/93652\n",
    "    submission = re.sub(r\"(http:\\/\\/www\\.|https:\\/\\/www\\.|http:\\/\\/|https:\\/\\/)?[a-z0-9]+([\\-\\.]{1}[a-z0-9]+)*\\.[a-z]{2,5}(:[0-9]{1,5})?(\\/[^ ]*)?\",\"\",submission)\n",
    "    \n",
    "    #source https://www.regextester.com/94502  \n",
    "    #submission = re.sub(r\"(?:http(s)?:\\/\\/)?[\\w.-]+(?:\\.[\\w\\.-]+)+[\\w\\-\\._~:/?#[\\]@!\\$&'\\(\\)\\*\\+,;=.%]+\",\"\",submission)\n",
    "    submission = re.sub(r\"(@\\[A-Za-z0-9]+)|&gt;|&amp;|#x200b;\",\"\",submission)\n",
    "\n",
    "    submission = re.sub(\"[/:\\-;*!?]+\", \" \", submission)\n",
    "    submission = re.sub(\"[.]{2,}\", \" \", submission)\n",
    "\n",
    "    submission = re.sub(r\"[^0-9A-Za-z' ]\",\"\",submission)\n",
    "    submission = \" \".join(contractions.fix(word) for word in submission.split())\n",
    "    submission = re.sub(r\"'s|â€™s|'\",\"\",submission)\n",
    "    submission = tokenizer.tokenize(submission)\n",
    "    lemmatized_submission = []   \n",
    "    for word in submission:\n",
    "        pos = get_pos_tag([word])\n",
    "        if pos == None or word in known_word_list:\n",
    "            lemmatized_submission.append(word)\n",
    "        else:\n",
    "            lemmatized_submission.append(lemmatizer.lemmatize(word, pos))\n",
    "    return lemmatized_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pos_tag(word):\n",
    "    pos = nltk.pos_tag(word)\n",
    "    if pos[0][1].startswith('J'):\n",
    "        return 'a'\n",
    "    elif pos[0][1].startswith('V'):\n",
    "        return 'v'\n",
    "    elif pos[0][1].startswith('R'):\n",
    "        return 'r'\n",
    "    elif pos[0][1].startswith('N'):\n",
    "        return 'n'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "apply preprocessing on title and selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe['title'] = dataframe['title'].apply(preprocessing)\n",
    "dataframe['selftext'] = dataframe['selftext'].apply(preprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = [\"ukraine\", \"ukrainian\", \"ukraini\", \"russia\", \"russian\", \"putin\", \"zelensky\", \"zelenskyy\", \"nato\", \"kiev\", \"kyiv\", \"sanction\", \"oil\", \"gas\", \"swift\", \"moscow\", \"kremlin\", \"azov\", \"vladimir\", \"war\"]\n",
    "\n",
    "def checkForWords(array):\n",
    "    for word in wordlist:\n",
    "        if word in array:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter only for submissions where either title or self text contains certain ukraine war related words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36737, 89)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25590, 89)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(dataframe.shape)\n",
    "filtered_dataframe = dataframe.loc[dataframe[\"title\"].apply(checkForWords) | dataframe[\"selftext\"].apply(checkForWords)]\n",
    "filtered_dataframe['title'] = filtered_dataframe['title'].apply(\" \".join)\n",
    "filtered_dataframe['selftext'] = filtered_dataframe['selftext'].apply(\" \".join)\n",
    "filtered_dataframe.to_csv(f'./data/{SUBREDDIT}_preprocessed_filtered.csv', header=True, index=False, columns=list(filtered_dataframe.axes[1]), encoding='utf-8')\n",
    "filtered_dataframe.shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b552e9e2291ee47d97a6f9068176d4d60c8957403441ee997b7a7bce0cd7c764"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
